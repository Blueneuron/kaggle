{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/alyssa/.virtualenvs/fastai/lib/python3.6/site-packages/sklearn/cross_validation.py:41: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "# https://www.kaggle.com/c/house-prices-advanced-regression-techniques\n",
    "\n",
    "# Stacking Starter based on Allstate Faron's Script\n",
    "# https://www.kaggle.com/mmueller/allstate-claims-severity/stacking-starter/run/390867\n",
    "# Preprocessing from Alexandru Papiu\n",
    "# https://www.kaggle.com/apapiu/house-prices-advanced-regression-techniques/regularized-linear-models\n",
    "\n",
    "import os.path\n",
    "import math\n",
    "import functools\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy.stats import skew\n",
    "\n",
    "import xgboost as xgb\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.ensemble import ExtraTreesRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.linear_model import Ridge, RidgeCV, ElasticNet, LassoCV, Lasso\n",
    "from sklearn.svm import SVR, NuSVR\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.feature_selection import f_regression, mutual_info_regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((1460, 80), (1459, 80), (1460,))"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TARGET = 'SalePrice'\n",
    "NSPLITS = 5\n",
    "SEED = 0\n",
    "NROWS = None\n",
    "data_dir = functools.partial(os.path.join, 'data/')\n",
    "SUBMISSION_FILE = data_dir('sample_submission.csv')\n",
    "\n",
    "\n",
    "## Load the data ##\n",
    "train = pd.read_csv(data_dir('train.csv'))\n",
    "test = pd.read_csv(data_dir('test.csv'))\n",
    "\n",
    "# Separate the labels from the last column\n",
    "labels = train[TARGET]\n",
    "y_train = np.log(labels + 1)\n",
    "train.drop([TARGET], axis=1, inplace=True)\n",
    "\n",
    "ntrain = train.shape[0]\n",
    "ntest = test.shape[0]\n",
    "\n",
    "train.shape, test.shape, y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([  1300,   1470,   1476, ..., 159000, 164660, 215245])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_data = pd.concat([train, test])\n",
    "values = all_data['LotArea'].unique()\n",
    "values.sort()\n",
    "values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def digitize(all_data, column):\n",
    "    values = all_data[column].unique()\n",
    "    values.sort()\n",
    "    return np.digitize(all_data[column], bins=values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((1460, 288), (1459, 288))"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Preprocessing ##\n",
    "#all_data = pd.concat([train, test])\n",
    "#all_data.drop(['Id'], axis=1, inplace=True)\n",
    "\n",
    "all_data = pd.concat((train.loc[:,'MSSubClass':'SaleCondition'],\n",
    "                      test.loc[:,'MSSubClass':'SaleCondition']))\n",
    "\n",
    "#for col in ['MSSubClass']: #, 'YearBuilt', 'YearRemodAdd', 'MoSold', 'YrSold']:\n",
    "#    all_data[col] = digitize(all_data, col)\n",
    "\n",
    "#log transform skewed numeric features:\n",
    "numeric_feats = all_data.dtypes[all_data.dtypes != 'object'].index\n",
    "object_feats = all_data.dtypes[all_data.dtypes == 'object'].index\n",
    "#object_feats = np.hstack([object_feats, ['MSSubClass', 'YearBuilt', 'YearRemodAdd', 'MoSold', 'YrSold']])\n",
    "\n",
    "skewed_feats = train[numeric_feats].apply(lambda x: skew(x.dropna())) #compute skewness\n",
    "skewed_feats = skewed_feats[skewed_feats > 0.7]\n",
    "skewed_feats = skewed_feats.index\n",
    "\n",
    "all_data[skewed_feats] = np.log1p(all_data[skewed_feats])\n",
    "all_data = all_data.fillna(all_data.median())\n",
    "all_data = pd.get_dummies(all_data, columns=object_feats)\n",
    "\n",
    "#creating matrices for sklearn:\n",
    "data = all_data.values\n",
    "x_train = data[:ntrain]\n",
    "x_test = data[ntrain:]\n",
    "\n",
    "\n",
    "x_train.shape, x_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# mi = mutual_info_regression(x_train, labels, random_state=SEED)\n",
    "# mi /= np.max(mi)\n",
    "\n",
    "# data = all_data.loc[:, mi > 0].values\n",
    "# x_train = data[:ntrain]\n",
    "# x_test = data[ntrain:]\n",
    "# x_train.shape, x_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "XG-CV: 0.12257812904190073\n",
      "ET-CV: 0.14555761485208646\n",
      "RF-CV: 0.14241118123674068\n",
      "RD-CV: 0.13182895036747352\n",
      "LS-CV: 0.1432176643227663\n",
      "SVR-CV: 0.2511859720627804\n",
      "KNR-CV: 0.2520716462695527\n",
      "(1460, 7),(1459, 7)\n",
      "[0]\ttrain-rmse:11.4159+0.00809367\ttest-rmse:11.4158+0.0328669\n",
      "[50]\ttrain-rmse:6.91854+0.00502096\ttest-rmse:6.91878+0.0340042\n",
      "[100]\ttrain-rmse:4.19619+0.00323592\ttest-rmse:4.19648+0.027922\n",
      "[150]\ttrain-rmse:2.54772+0.00181997\ttest-rmse:2.54795+0.0238884\n",
      "[200]\ttrain-rmse:1.55071+0.00150019\ttest-rmse:1.55098+0.0206877\n",
      "[250]\ttrain-rmse:0.948899+0.00119081\ttest-rmse:0.94926+0.0187307\n",
      "[300]\ttrain-rmse:0.587603+0.00147743\ttest-rmse:0.588662+0.0178137\n",
      "[350]\ttrain-rmse:0.373694+0.00186282\ttest-rmse:0.375705+0.0177032\n",
      "[400]\ttrain-rmse:0.25022+0.0024844\ttest-rmse:0.253451+0.0180608\n",
      "[450]\ttrain-rmse:0.182257+0.00333903\ttest-rmse:0.186978+0.0187799\n",
      "[500]\ttrain-rmse:0.147075+0.00397375\ttest-rmse:0.153134+0.0195568\n",
      "[550]\ttrain-rmse:0.129673+0.00438892\ttest-rmse:0.136977+0.0198599\n",
      "[600]\ttrain-rmse:0.12092+0.00472016\ttest-rmse:0.129362+0.0200075\n",
      "[650]\ttrain-rmse:0.116199+0.00493256\ttest-rmse:0.125612+0.0200565\n",
      "[700]\ttrain-rmse:0.113271+0.00501064\ttest-rmse:0.123532+0.0201505\n",
      "[750]\ttrain-rmse:0.111293+0.00501386\ttest-rmse:0.122213+0.020203\n",
      "[800]\ttrain-rmse:0.109793+0.00496095\ttest-rmse:0.121573+0.0204111\n",
      "[850]\ttrain-rmse:0.10858+0.00490793\ttest-rmse:0.120919+0.0206133\n",
      "[900]\ttrain-rmse:0.10761+0.00482834\ttest-rmse:0.120497+0.0207793\n",
      "[950]\ttrain-rmse:0.106784+0.0047597\ttest-rmse:0.12015+0.0209598\n",
      "[1000]\ttrain-rmse:0.106099+0.00470162\ttest-rmse:0.1199+0.0211152\n",
      "[1050]\ttrain-rmse:0.105547+0.00466792\ttest-rmse:0.119781+0.0212108\n",
      "[1100]\ttrain-rmse:0.105066+0.00463755\ttest-rmse:0.11967+0.02141\n",
      "Ensemble-CV: 0.1196574+0.02140162377577926\n"
     ]
    }
   ],
   "source": [
    "kf = KFold(n_splits=NSPLITS, shuffle=True, random_state=SEED)\n",
    "\n",
    "class SklearnWrapper(object):\n",
    "    def __init__(self, clf, seed=0, params=None):\n",
    "        if params is None:\n",
    "            params = {}\n",
    "        self.clf = clf(**params)\n",
    "\n",
    "    def train(self, x_train, y_train):\n",
    "        self.clf.fit(x_train, y_train)\n",
    "\n",
    "    def predict(self, x):\n",
    "        return self.clf.predict(x)\n",
    "\n",
    "\n",
    "class XgbWrapper(object):\n",
    "    def __init__(self, seed=0, params=None):\n",
    "        self.param = params\n",
    "        self.param['seed'] = seed\n",
    "        self.nrounds = params.pop('nrounds', 250)\n",
    "\n",
    "    def train(self, x_train, y_train):\n",
    "        dtrain = xgb.DMatrix(x_train, label=y_train)\n",
    "        self.gbdt = xgb.train(self.param, dtrain, self.nrounds)\n",
    "\n",
    "    def predict(self, x):\n",
    "        return self.gbdt.predict(xgb.DMatrix(x))\n",
    "\n",
    "\n",
    "def get_oof(clf):\n",
    "    oof_train = np.zeros((ntrain,))\n",
    "    oof_test = np.zeros((ntest,))\n",
    "    oof_test_skf = np.empty((NSPLITS, ntest))\n",
    "\n",
    "    for i, (train_index, test_index) in enumerate(kf.split(x_train)):\n",
    "        \n",
    "        x_tr = x_train[train_index]\n",
    "        y_tr = y_train[train_index]\n",
    "        x_te = x_train[test_index]\n",
    "\n",
    "        clf.train(x_tr, y_tr)\n",
    "\n",
    "        oof_train[test_index] = clf.predict(x_te)\n",
    "        oof_test_skf[i, :] = clf.predict(x_test)\n",
    "\n",
    "    oof_test[:] = oof_test_skf.mean(axis=0)\n",
    "    return oof_train.reshape(-1, 1), oof_test.reshape(-1, 1)\n",
    "\n",
    "\n",
    "et_params = {\n",
    "    'n_jobs': 16,\n",
    "    'n_estimators': 100,\n",
    "    'max_features': 0.5,\n",
    "    'max_depth': 12,\n",
    "    'min_samples_leaf': 2,\n",
    "    'random_state': SEED\n",
    "}\n",
    "\n",
    "rf_params = {\n",
    "    'n_jobs': 16,\n",
    "    'n_estimators': 100,\n",
    "    'max_features': 0.2,\n",
    "    'max_depth': 12,\n",
    "    'min_samples_leaf': 2,\n",
    "    'random_state': SEED\n",
    "}\n",
    "\n",
    "xgb_params = {\n",
    "    'seed': 0,\n",
    "    'colsample_bytree': 0.7,\n",
    "    'silent': 1,\n",
    "    'subsample': 0.7,\n",
    "    'learning_rate': 0.075,\n",
    "    'objective': 'reg:linear',\n",
    "    'max_depth': 4,\n",
    "    'num_parallel_tree': 1,\n",
    "    'min_child_weight': 1,\n",
    "    'eval_metric': 'rmse',\n",
    "    'nrounds': 1000,\n",
    "    'random_state': SEED\n",
    "}\n",
    "\n",
    "rd_params={\n",
    "    'alpha': 10,\n",
    "    'random_state': SEED\n",
    "}\n",
    "\n",
    "\n",
    "ls_params={\n",
    "    'alpha': 0.005,\n",
    "    'random_state': SEED\n",
    "}\n",
    "\n",
    "knr_params = {\n",
    "    'n_neighbors': 10\n",
    "}\n",
    "\n",
    "xg = XgbWrapper(seed=SEED, params=xgb_params)\n",
    "et = SklearnWrapper(clf=ExtraTreesRegressor, seed=SEED, params=et_params)\n",
    "rf = SklearnWrapper(clf=RandomForestRegressor, seed=SEED, params=rf_params)\n",
    "rd = SklearnWrapper(clf=Ridge, seed=SEED, params=rd_params)\n",
    "ls = SklearnWrapper(clf=Lasso, seed=SEED, params=ls_params)\n",
    "svr = SklearnWrapper(clf=NuSVR, seed=SEED)\n",
    "knr = SklearnWrapper(clf=KNeighborsRegressor, seed=SEED, params=knr_params)\n",
    "\n",
    "xg_oof_train, xg_oof_test = get_oof(xg)\n",
    "et_oof_train, et_oof_test = get_oof(et)\n",
    "rf_oof_train, rf_oof_test = get_oof(rf)\n",
    "rd_oof_train, rd_oof_test = get_oof(rd)\n",
    "ls_oof_train, ls_oof_test = get_oof(ls)\n",
    "svr_oof_train, svr_oof_test = get_oof(svr)\n",
    "knr_oof_train, knr_oof_test = get_oof(knr)\n",
    "\n",
    "print(\"XG-CV: {}\".format(np.sqrt(mean_squared_error(y_train, xg_oof_train))))\n",
    "print(\"ET-CV: {}\".format(np.sqrt(mean_squared_error(y_train, et_oof_train))))\n",
    "print(\"RF-CV: {}\".format(np.sqrt(mean_squared_error(y_train, rf_oof_train))))\n",
    "print(\"RD-CV: {}\".format(np.sqrt(mean_squared_error(y_train, rd_oof_train))))\n",
    "print(\"LS-CV: {}\".format(np.sqrt(mean_squared_error(y_train, ls_oof_train))))\n",
    "print(\"SVR-CV: {}\".format(np.sqrt(mean_squared_error(y_train, svr_oof_train))))\n",
    "print(\"KNR-CV: {}\".format(np.sqrt(mean_squared_error(y_train, knr_oof_train))))\n",
    "\n",
    "x_train = np.concatenate((xg_oof_train, et_oof_train, rf_oof_train, rd_oof_train, ls_oof_train), axis=1)\n",
    "x_test = np.concatenate((xg_oof_test, et_oof_test, rf_oof_test, rd_oof_test, ls_oof_test), axis=1)\n",
    "\n",
    "print(\"{},{}\".format(x_train.shape, x_test.shape))\n",
    "\n",
    "dtrain = xgb.DMatrix(x_train, label=y_train)\n",
    "dtest = xgb.DMatrix(x_test)\n",
    "\n",
    "\n",
    "xgb_params = {\n",
    "    'seed': 0,\n",
    "    'colsample_bytree': 0.8,\n",
    "    'silent': 1,\n",
    "    'subsample': 0.6,\n",
    "    'learning_rate': 0.01,\n",
    "    'objective': 'reg:linear',\n",
    "    'max_depth': 1,\n",
    "    'num_parallel_tree': 1,\n",
    "    'min_child_weight': 1,\n",
    "    'eval_metric': 'rmse',\n",
    "}\n",
    "\n",
    "res = xgb.cv(xgb_params, dtrain, num_boost_round=1500, nfold=NSPLITS, seed=SEED, stratified=False,\n",
    "             early_stopping_rounds=25, verbose_eval=50, show_stdv=True)\n",
    "\n",
    "best_nrounds = res.shape[0] - 1\n",
    "cv_mean = res.iloc[-1, 0]\n",
    "cv_std = res.iloc[-1, 1]\n",
    "\n",
    "print('Ensemble-CV: {0}+{1}'.format(cv_mean, cv_std))\n",
    "\n",
    "gbdt = xgb.train(xgb_params, dtrain, best_nrounds)\n",
    "\n",
    "submission = pd.read_csv(SUBMISSION_FILE)\n",
    "submission[TARGET] = gbdt.predict(dtest)\n",
    "saleprice = np.exp(submission['SalePrice']) - 1\n",
    "submission[TARGET] = saleprice\n",
    "submission.to_csv(data_dir('xgstacker_starter_submission2.csv'), index=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Ensemble-CV: 0.12850675\n",
    "# Ensemble-CV: 0.1237075 (0.12236)\n",
    "# Ensemble-CV: 0.12549675 (0.12399)\n",
    "# Ensemble-CV: 0.125022 (0.12381)\n",
    "# Ensemble-CV: 0.12068925 (0.12133)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
